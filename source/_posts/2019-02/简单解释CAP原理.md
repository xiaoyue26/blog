---
title: 简单解释CAP原理
date: 2019-02-01 09:33:53
tags: 分布式
categories: 分布式

---

关于CAP原理的术语描述很多,其实给理解带来了障碍。(以下是维基百科:)
>一致性（Consistency）： （等同于所有节点访问同一份最新的数据副本）
可用性（Availability）：（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）
分区容错性（Partition tolerance）：（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。）
{% img /images/2019-02/cap.png 800 1200 cap %}
如图所示,CAP最多只能取两者。（如果每项要彻底达标，只能取2个，但也可以三者都不完全实现）

改成自然语言，通俗解释一下，就容易理解多了:
> C: 一致性。达成一致的速度足够快、或者每次更新是整个集群原子性的操作。如果有一个中控节点(单点瓶颈)，很容易让值变更是原子性的。(但也牺牲了A)
A: 可用性。 没有单点瓶颈，挂1，2个节点也能正常工作。
P: 可分性。 把集群切两半，让它们失联，让两半都能正常工作。

## 具体案例的CAP取舍
大部分的分布式系统(或者说集群)都是先取P，然后取舍A或者C（引入单点，或者使用P2P的协议）。

`lease机制`: CP。例如hdfs中pipeline写入,client先申请租约lease，然后写入3备份后才返回。一致性由client单点控制完成,P由3副本完成，牺牲了A（有单点）。
`Quorum机制`:C+0.5A+0.5P。N个副本，更新W个，读R个。
`2PC/两阶段提交`: C+0.1A+0.1P。
`Paxos`: C+0.8C+0.8P。

`redis-cluster`: AP。key的分布:用gossip协议(类似于p2p)达成一致性,因此C比较慢。
`redis-sentile`: CP。key的分布:各节点完全独立,数据存在哪里完全由客户端单点维护。因此没有A。
`codis`：CP。由代理单点维护key的分布，因此也没有A。

一个实际的系统可能涉及到很多分布式协议，因此每个部分对于CAP的取舍可能会有不同。
HDFS系统: CP。大部分看起来是有单点。
ceph系统: AP。大部分看起来是p2p的，
